{
  "name": "ogden",
  "version": "1.0.0",
  "description": "String tokenization for basic english",
  "main": "lib/ogden.js",
  "scripts": {
    "test": "grunt test"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/avoidwork/ogden.git"
  },
  "keywords": [
    "token",
    "tokenize",
    "tokenization",
    "words"
  ],
  "author": "Jason Mulligan <jason.mulligan@avoidwork.com>",
  "license": "BSD-3-Clause",
  "bugs": {
    "url": "https://github.com/avoidwork/ogden/issues"
  },
  "homepage": "http://avoidwork.github.io/ogden",
  "devDependencies": {
    "babel-eslint": "^4.1.4",
    "babel-preset-es2015": "^6.1.2",
    "grunt": "^0.4.5",
    "grunt-babel": "^6.0.0",
    "grunt-cli": "^0.1.13",
    "grunt-contrib-concat": "^0.1.3",
    "grunt-contrib-nodeunit": "^0.4.1",
    "grunt-contrib-uglify": "^0.9.1",
    "grunt-contrib-watch": "^0.2.0",
    "grunt-eslint": "^17.3.1",
    "grunt-sed": "^0.1.1"
  },
  "dependencies": {}
}
