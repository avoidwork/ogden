{
  "name": "ogden",
  "version": "2.0.0",
  "description": "Basic English tokenizer",
  "main": "lib/ogden.js",
  "scripts": {
    "test": "grunt test"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/avoidwork/ogden.git"
  },
  "keywords": [
    "token",
    "tokenize",
    "tokenization",
    "words"
  ],
  "author": "Jason Mulligan <jason.mulligan@avoidwork.com>",
  "license": "BSD-3-Clause",
  "bugs": {
    "url": "https://github.com/avoidwork/ogden/issues"
  },
  "homepage": "http://avoidwork.github.io/ogden",
  "devDependencies": {
    "babel-core": "^6.26.0",
    "babel-minify": "^0.2.0",
    "babel-preset-env": "^1.6.1",
    "grunt": "^1.0.1",
    "grunt-babel": "^7.0.0",
    "grunt-cli": "^1.2.0",
    "grunt-contrib-concat": "^1.0.1",
    "grunt-contrib-nodeunit": "^1.0.0",
    "grunt-contrib-uglify": "^3.1.0",
    "grunt-contrib-watch": "^1.0.0",
    "grunt-eslint": "^20.1.0",
    "grunt-replace": "^1.0.1"
  },
  "dependencies": {}
}
